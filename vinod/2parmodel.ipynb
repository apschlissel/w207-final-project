{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45e3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten \n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6d1a8",
   "metadata": {},
   "source": [
    "# Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06d2cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "resized\n",
      "resnet and tags processing\n",
      "Training Shape: (9912, 50, 50, 3)\n",
      "Labels Shape; (9912,)\n",
      "<bound method NDFrame.head of                                     Id  Subject Focus  Eyes  Face  Near  \\\n",
      "0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n",
      "1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n",
      "2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n",
      "3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n",
      "4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n",
      "...                                ...            ...   ...   ...   ...   \n",
      "9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n",
      "9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n",
      "9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n",
      "9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n",
      "9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n",
      "\n",
      "      Action  Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
      "0          0          0      1        0      0          0     0     0   \n",
      "1          0          0      0        0      0          0     0     0   \n",
      "2          0          0      0        0      1          1     0     0   \n",
      "3          0          0      0        0      0          0     0     0   \n",
      "4          0          0      1        0      0          0     0     0   \n",
      "...      ...        ...    ...      ...    ...        ...   ...   ...   \n",
      "9907       0          0      0        0      0          0     0     1   \n",
      "9908       0          0      0        0      0          0     0     0   \n",
      "9909       0          0      0        0      1          1     0     0   \n",
      "9910       0          0      0        0      1          0     0     0   \n",
      "9911       0          0      0        0      0          0     0     0   \n",
      "\n",
      "      Pawpularity                                               path  \\\n",
      "0              63  ../petfinder-pawpularity-score/train/0007de188...   \n",
      "1              42  ../petfinder-pawpularity-score/train/0009c66b9...   \n",
      "2              28  ../petfinder-pawpularity-score/train/0013fd999...   \n",
      "3              15  ../petfinder-pawpularity-score/train/0018df346...   \n",
      "4              72  ../petfinder-pawpularity-score/train/001dc955e...   \n",
      "...           ...                                                ...   \n",
      "9907           15  ../petfinder-pawpularity-score/train/ffbfa0383...   \n",
      "9908           70  ../petfinder-pawpularity-score/train/ffcc8532d...   \n",
      "9909           20  ../petfinder-pawpularity-score/train/ffdf2e867...   \n",
      "9910           20  ../petfinder-pawpularity-score/train/fff19e2ce...   \n",
      "9911           30  ../petfinder-pawpularity-score/train/fff8e47c7...   \n",
      "\n",
      "                                                    img  cuteness_bin  \\\n",
      "0     <PIL.Image.Image image mode=RGB size=50x50 at ...             6   \n",
      "1     <PIL.Image.Image image mode=RGB size=50x50 at ...             4   \n",
      "2     <PIL.Image.Image image mode=RGB size=50x50 at ...             2   \n",
      "3     <PIL.Image.Image image mode=RGB size=50x50 at ...             1   \n",
      "4     <PIL.Image.Image image mode=RGB size=50x50 at ...             7   \n",
      "...                                                 ...           ...   \n",
      "9907  <PIL.Image.Image image mode=RGB size=50x50 at ...             1   \n",
      "9908  <PIL.Image.Image image mode=RGB size=50x50 at ...             6   \n",
      "9909  <PIL.Image.Image image mode=RGB size=50x50 at ...             1   \n",
      "9910  <PIL.Image.Image image mode=RGB size=50x50 at ...             1   \n",
      "9911  <PIL.Image.Image image mode=RGB size=50x50 at ...             2   \n",
      "\n",
      "                                              img_array  \n",
      "0     [[[0.6666667, 0.65882355, 0.70980394], [0.6705...  \n",
      "1     [[[0.56078434, 0.54901963, 0.5764706], [0.5137...  \n",
      "2     [[[0.6862745, 0.67058825, 0.5254902], [0.69803...  \n",
      "3     [[[0.8509804, 0.88235295, 0.89411765], [0.8549...  \n",
      "4     [[[0.4509804, 0.45490196, 0.45490196], [0.5450...  \n",
      "...                                                 ...  \n",
      "9907  [[[0.78039217, 0.77254903, 0.7647059], [0.7803...  \n",
      "9908  [[[0.87058824, 0.83137256, 0.8], [0.85882354, ...  \n",
      "9909  [[[0.8862745, 0.89411765, 0.88235295], [0.8862...  \n",
      "9910  [[[0.4745098, 0.4627451, 0.37254903], [0.56078...  \n",
      "9911  [[[0.68235296, 0.68235296, 0.6627451], [0.6627...  \n",
      "\n",
      "[9912 rows x 18 columns]>\n",
      "[0 1 1 1 0 1 0 0 0 0 0]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# importing and resizing image data \n",
    "# change path to wherever your data lives on your computer\n",
    "csv_path = \"../petfinder-pawpularity-score/train.csv\"\n",
    "image_path = '../petfinder-pawpularity-score/train/'\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "def CutenessBuckets(pawpularity_score):\n",
    "    if pawpularity_score <= 10:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 20:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 30:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 40:\n",
    "        return 3\n",
    "    elif pawpularity_score <= 50:\n",
    "        return 4\n",
    "    elif pawpularity_score <= 60:\n",
    "        return 5\n",
    "    elif pawpularity_score <= 70:\n",
    "        return 6\n",
    "    elif pawpularity_score <= 80:\n",
    "        return 7\n",
    "    elif pawpularity_score <= 90:\n",
    "        return 8\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 9\n",
    "\n",
    "def getAdditionalTags(model, imArr):\n",
    "    tags=[]\n",
    "    im = np.expand_dims(imArr, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    preds = model.predict(im)\n",
    "    #print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "    return decode_predictions(preds, top=3)[0][0][0], decode_predictions(preds, top=3)[0][1][0], decode_predictions(preds, top=3)[0][2][0] \n",
    "    #return tags\n",
    "\n",
    "def CleanandProcessData(csv_path, image_path, image_resize):\n",
    "\n",
    "    # creating path to image using the id in the data frame we've created\n",
    "    df['path'] = image_path + df['Id'] + '.jpg'\n",
    "    df['img'] = df['path'].apply(lambda x: Image.open(x).convert(\"RGB\").resize((image_resize,image_resize)))\n",
    "    print('resized')\n",
    "    df['cuteness_bin'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "    df['img_array'] = df['img'].apply(lambda x: img_to_array(x)/255)\n",
    "\n",
    "    labels_raw=[]\n",
    "    labels_bin = []\n",
    "    imgArr=[]\n",
    "    tags=[]\n",
    "    print('resnet and tags processing')\n",
    "    for ind in df.index:\n",
    "        tags_data=[]\n",
    "        img = df.img_array[0]\n",
    "        #t1,t2,t3=getAdditionalTags(model, img)\n",
    "        imgArr.append(img)\n",
    "        labels_raw.append(df['Pawpularity'][ind])\n",
    "        labels_bin.append(df['cuteness_bin'][ind])\n",
    "        #append all metadata in the dataframe as tags\n",
    "        tags_data.append(df['Subject Focus'][ind])\n",
    "        tags_data.append(df['Eyes'][ind])\n",
    "        tags_data.append(df['Face'][ind])\n",
    "        tags_data.append(df['Near'][ind])\n",
    "        tags_data.append(df['Accessory'][ind])\n",
    "        tags_data.append(df['Group'][ind])\n",
    "        tags_data.append(df['Collage'][ind])\n",
    "        tags_data.append(df['Human'][ind])\n",
    "        tags_data.append(df['Occlusion'][ind])\n",
    "        tags_data.append(df['Info'][ind])\n",
    "        tags_data.append(df['Blur'][ind])            \n",
    "        tags.append(np.array(tags_data, dtype=int))\n",
    "    #print(tags_data)\n",
    "    labels_raw = np.array(labels_raw)\n",
    "    labels_bin = np.array(labels_bin)\n",
    "    tags= np.array(tags,dtype=int)\n",
    "\n",
    "    X_train=np.array(imgArr, dtype=float)\n",
    "    print('Training Shape:',X_train.shape)\n",
    "    print('Labels Shape;', labels_raw.shape)\n",
    "    return X_train, labels_raw, labels_bin, tags\n",
    "\n",
    "# imnporting csv with image ids and pawpularity scores\n",
    "print('2')\n",
    "df = pd.read_csv(csv_path)\n",
    "X_train, labels_raw, labels_bin, tags = CleanandProcessData(csv_path, image_path, 50)\n",
    "print(df.head)\n",
    "print(tags[0])\n",
    "print (type(tags))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-species",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600ca3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling\n",
      "shuffled\n",
      "data shape:  (9912, 50, 50, 3)\n",
      "pawpularity label shape: (9912,)\n",
      "bin label shape: (9912,)\n",
      "tags  shape: (9912, 11)\n",
      "test_labels_raw (996,)\n",
      "train_labels_raw (7921,)\n",
      "dev_labels_raw (996,)\n",
      "test_labels_category (996, 101)\n",
      "train_labels_category (7921, 101)\n",
      "dev_labels_category (996, 101)\n"
     ]
    }
   ],
   "source": [
    "print('shuffling')\n",
    "# Shuffling data and separating into train, test and dev sets\n",
    "shuffle = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, labels_raw, labels_bin, tags = X_train[shuffle], labels_raw[shuffle], labels_bin[shuffle], tags[shuffle]\n",
    "print('shuffled')\n",
    "print('data shape: ', X_train.shape)\n",
    "print('pawpularity label shape:', labels_raw.shape)\n",
    "print('bin label shape:', labels_bin.shape)\n",
    "print('tags  shape:', tags.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "train_data, train_labels_raw, train_labels_bin, train_tags = X_train[:7921], labels_raw[:7921], labels_bin[:7921], tags[:7921]\n",
    "test_data, test_labels_raw, test_labels_bin, test_tags = X_train[8916:], labels_raw[8916:], labels_bin[8916:], tags[8916:]\n",
    "dev_data, dev_labels_raw, dev_labels_bin, dev_tags = X_train[7920:8916], labels_raw[7920:8916], labels_bin[7920:8916], tags[7920:8916]\n",
    "\n",
    "print('test_labels_raw', test_labels_raw.shape)\n",
    "print('train_labels_raw', train_labels_raw.shape)\n",
    "print('dev_labels_raw', dev_labels_raw.shape)\n",
    "\n",
    "# raw labels (ie original pawpularity score)\n",
    "test_labels_category = to_categorical(test_labels_raw)\n",
    "train_labels_category = to_categorical(train_labels_raw)\n",
    "dev_labels_category = to_categorical(dev_labels_raw)\n",
    "\n",
    "print('test_labels_category', test_labels_category.shape)\n",
    "print('train_labels_category', train_labels_category.shape)\n",
    "print('dev_labels_category', dev_labels_category.shape)\n",
    "\n",
    "# bucketed labels \n",
    "test_labels_bins_category = to_categorical(test_labels_bin)\n",
    "train_labels_bins_category = to_categorical(train_labels_bin)\n",
    "dev_labels_bins_category = to_categorical(dev_labels_bin)\n",
    "\n",
    "# blurred image data (optional use)\n",
    "blurred_train = gaussian_filter(train_data, sigma=1)\n",
    "blurred_test = gaussian_filter(test_data, sigma = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ee56d",
   "metadata": {},
   "source": [
    "# First CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3e2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- CNN Model 1 with all Paw scores ----------\n",
      "train_data (7921, 50, 50, 3)\n",
      "train_lables_cat (7921, 101)\n",
      "test_data (996, 50, 50, 3)\n",
      "test_lables_cat (996, 101)\n",
      "Epoch 1/3\n",
      "248/248 [==============================] - 29s 113ms/step - loss: 4.2656 - accuracy: 0.0276 - val_loss: 4.2411 - val_accuracy: 0.0361\n",
      "Epoch 2/3\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 4.2260 - accuracy: 0.0288 - val_loss: 4.2148 - val_accuracy: 0.0311\n",
      "Epoch 3/3\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 4.2148 - accuracy: 0.0304 - val_loss: 4.2060 - val_accuracy: 0.0371\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 4.2060 - accuracy: 0.0371\n",
      "\n",
      "Test loss: 4.206021785736084\n",
      "Test accuracy: 0.03714859485626221\n"
     ]
    }
   ],
   "source": [
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "possible_outcomes = 101\n",
    "# first model attempt (using raw pawpularity scores)\n",
    "# switch out activation to 'sigmoid'\n",
    "# try different pixel amounts (100x100) (20x20) etc\n",
    "#try binary crosstentropy vs categorical \n",
    "#adjust epochs\n",
    "\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer with 20 filters\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    \n",
    "# add 2D pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "# flatten data\n",
    "model.add(Flatten())\n",
    "    \n",
    "# add a dense all-to-all relu layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "# apply dropout with rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "# soft-max layer\n",
    "model.add(Dense(possible_outcomes, activation='softmax'))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "\n",
    "print('-'*10, 'CNN Model 1 with all Paw scores', '-'*10)\n",
    "print(\"train_data\",train_data.shape )\n",
    "print(\"train_lables_cat\",train_labels_category.shape )\n",
    "print(\"test_data\",test_data.shape )\n",
    "print(\"test_lables_cat\",test_labels_category.shape )\n",
    "\n",
    "model.fit(train_data,train_labels_category, validation_data=(test_data, test_labels_category), epochs=3)\n",
    "# evaluate the model\n",
    "score = model.evaluate(test_data, test_labels_category, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119c77f",
   "metadata": {},
   "source": [
    "# Same Model but using 10 category buckets for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93f6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- CNN Model 1 with all Paw scores ----------\n",
      "Epoch 1/3\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 2.0004 - accuracy: 0.2613 - val_loss: 1.9922 - val_accuracy: 0.2922\n",
      "Epoch 2/3\n",
      "248/248 [==============================] - 23s 93ms/step - loss: 1.9806 - accuracy: 0.2729 - val_loss: 1.9790 - val_accuracy: 0.2922\n",
      "Epoch 3/3\n",
      "248/248 [==============================] - 23s 95ms/step - loss: 1.9723 - accuracy: 0.2772 - val_loss: 1.9691 - val_accuracy: 0.2922\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.9691 - accuracy: 0.2922\n",
      "\n",
      "Test loss: 1.969141960144043\n",
      "Test accuracy: 0.29216867685317993\n"
     ]
    }
   ],
   "source": [
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "possible_outcomes = 10\n",
    "# first model attempt (using raw pawpularity scores)\n",
    "# switch out activation to 'sigmoid'\n",
    "# try different pixel amounts (100x100) (20x20) etc\n",
    "#try binary crosstentropy vs categorical \n",
    "#adjust epochs\n",
    "\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer with 20 filters\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    \n",
    "# add 2D pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "# flatten data\n",
    "model.add(Flatten())\n",
    "    \n",
    "# add a dense all-to-all relu layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "# apply dropout with rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "# soft-max layer\n",
    "model.add(Dense(possible_outcomes, activation='softmax'))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "\n",
    "print('-'*10, 'CNN Model 1 with all Paw scores', '-'*10)\n",
    "model.fit(train_data,train_labels_bins_category, validation_data=(test_data, test_labels_bins_category), epochs=3)\n",
    "# evaluate the model\n",
    "score = model.evaluate(test_data, test_labels_bins_category, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c8e2d",
   "metadata": {},
   "source": [
    "# 2Parameter Second CNN Model - Using raw paw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0dfc208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7921, 11)\n",
      "(7921, 50, 50, 3)\n",
      "(7921, 101)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/3\n",
      "198/198 [==============================] - 12s 53ms/step - loss: 0.2281 - rmse: 0.1077 - mae: 0.0186 - mape: 8810581.0000 - val_loss: 0.2042 - val_rmse: 0.1011 - val_mae: 0.0238 - val_mape: 14001861.0000\n",
      "Epoch 2/3\n",
      "198/198 [==============================] - 10s 52ms/step - loss: 0.1850 - rmse: 0.0990 - mae: 0.0196 - mape: 9802909.0000 - val_loss: 0.1672 - val_rmse: 0.0990 - val_mae: 0.0196 - val_mape: 9802953.0000\n",
      "Epoch 3/3\n",
      "198/198 [==============================] - 11s 53ms/step - loss: 0.1517 - rmse: 0.0990 - mae: 0.0196 - mape: 9802975.0000 - val_loss: 0.1370 - val_rmse: 0.0990 - val_mae: 0.0196 - val_mape: 9802953.0000\n",
      "32/32 [==============================] - 1s 15ms/step - loss: 0.1370 - rmse: 0.0990 - mae: 0.0196 - mape: 9802959.0000\n",
      "Test accuracy: 0.09900990128517151\n"
     ]
    }
   ],
   "source": [
    "# model from kaggle page \n",
    "# https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1\n",
    "\n",
    "print(train_tags.shape)\n",
    "print(train_data.shape)\n",
    "print(train_labels_category.shape)\n",
    "print(type(train_tags))\n",
    "print(type(train_data))\n",
    "print(type(train_labels_category))\n",
    "# this accuracy seems ot be higher we could mess around with different filters/padding etc\n",
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "tags_input = tf.keras.Input(shape=(train_tags.shape[1],))\n",
    "#start off with x just being those inputs\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.Model(inputs=inputs, outputs=tf.keras.layers.Dense(1)(x))\n",
    "\n",
    "y = tags_input\n",
    "y = tf.keras.layers.Dense(11, activation=\"relu\")(y)\n",
    "y = tf.keras.layers.Dense(5, activation=\"relu\")(y)\n",
    "y = tf.keras.Model(inputs=tags_input, outputs=y) \n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = tf.keras.layers.concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model2 = tf.keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "#model = tf.keras.Model(inputs = [inputs], outputs = output)\n",
    "#model2 = tf.keras.Model(inputs = [inputs, tags_input], outputs = output)\n",
    "\n",
    "model2.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "x1=tf.convert_to_tensor(train_data)\n",
    "x2=tf.convert_to_tensor(train_tags)\n",
    "sx1=tf.convert_to_tensor(test_data)\n",
    "sx2=tf.convert_to_tensor(test_tags)\n",
    "\n",
    "model2.fit(x=[x1,x2], y=tf.convert_to_tensor(train_labels_category), batch_size=32, epochs=3, validation_split=0.2)\n",
    "score = model2.evaluate(x=[sx1,sx2], y=test_labels_category, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2414c",
   "metadata": {},
   "source": [
    "# 2Parameter Second CNN Model - Using bucket paw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bdb44a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26268e4e476d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# combine the output of the two branches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m# apply a FC layer and then a regression prediction on the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# combined outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "# model from kaggle page \n",
    "# https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1\n",
    "\n",
    "# this accuracy seems ot be higher we could mess around with different filters/padding etc\n",
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "tags_input = tf.keras.Input(shape=(train_tags.shape[1],))\n",
    "\n",
    "#start off with x just being those inputs\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "y = tags_input\n",
    "y = tf.keras.layers.Dense(11, activation=\"relu\")(y)\n",
    "y = tf.keras.layers.Dense(5, activation=\"relu\")(y)\n",
    "y = tf.keras.Model(inputs=tags_input, outputs=y) \n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = tf.keras.layers.concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model2 = tf.keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model2.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "x1=tf.convert_to_tensor(train_data)\n",
    "x2=tf.convert_to_tensor(train_tags)\n",
    "sx1=tf.convert_to_tensor(test_data)\n",
    "sx2=tf.convert_to_tensor(test_tags)\n",
    "\n",
    "model2.fit(x=[x1,x2], y=tf.convert_to_tensor(train_labels_bins_category), batch_size=32, epochs=3, validation_split=0.2)\n",
    "score = model2.evaluate(x=[sx1,sx2], y=test_labels_bins_category, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#model = tf.keras.Model(inputs = [inputs, tags_input], outputs = output)\n",
    "\n",
    "#model.compile(\n",
    "#    loss = 'mse', \n",
    "#    optimizer = 'Adam', \n",
    "#    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "#data_augmentation = ImageDataGenerator(\n",
    "#    rotation_range = 15, \n",
    "#    zoom_range = 0.15,\n",
    "#    width_shift_range = 0.2, \n",
    "#    height_shift_range = 0.2, \n",
    "#    shear_range = 0.1,\n",
    "#    horizontal_flip = True, \n",
    "#    fill_mode = \"nearest\")\n",
    "#history = model.fit(\n",
    "#    data_augmentation.flow(train_data,train_labels_bins_category,batch_size=32),\n",
    "#    validation_data = (test_data, test_labels_bins_category),\n",
    "#    steps_per_epoch = len(train_data) // 32,\n",
    "#    epochs = 3\n",
    "#)\n",
    "#score = model.evaluate(test_data, test_labels_bins_category, verbose=1)\n",
    "#print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-listening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
