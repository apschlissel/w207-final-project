{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "#visualizations to be used.... maybe.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_id_to_path(x):\n",
    "    return '../petfinder-pawpularity-score/train/' + x + \".jpg\"\n",
    "def test_id_to_path(x):\n",
    "    return '../petfinder-pawpularity-score/test/' + x + \".jpg\"\n",
    "\n",
    "\n",
    "train = pd.read_csv('../petfinder-pawpularity-score/train2.csv')\n",
    "train = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n",
    "\n",
    "test = pd.read_csv('../petfinder-pawpularity-score/test2.csv')\n",
    "test = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n",
    "\n",
    "train[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\n",
    "test[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "#Set the size image to 128 x 128\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "\n",
    "def path_to_eagertensor(image_path):\n",
    "    '''\n",
    "    Function that accepts an img url and returns an eager tensor\n",
    "    '''\n",
    "    raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(raw, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    return image\n",
    "\n",
    "X = []\n",
    "for img in train['img_path']: #Converting the paths to eager tensors into array X\n",
    "    new_img_tensor = path_to_eagertensor(img)\n",
    "    X.append(new_img_tensor)\n",
    "    \n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (8913, 128, 128, 3) \n",
      "X test shape: (991, 128, 128, 3) \n",
      "Y train shape: (8913,) \n",
      "Y test shape: (991,)\n"
     ]
    }
   ],
   "source": [
    "y = train['Pawpularity']\n",
    "#print(type(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12345) #Splitting the data into the appropriate bins for x and y training and test\n",
    "print(\"X train shape:\",x_train.shape, \"\\nX test shape:\", x_test.shape, \"\\nY train shape:\", y_train.shape, \"\\nY test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "278/278 [==============================] - 58s 207ms/step - loss: 503.2297 - accuracy: 4.5040e-04 - mse: 502.9815 - val_loss: 428.2518 - val_accuracy: 0.0000e+00 - val_mse: 427.9980\n",
      "Epoch 2/3\n",
      "278/278 [==============================] - 56s 203ms/step - loss: 476.3538 - accuracy: 4.5040e-04 - mse: 476.0965 - val_loss: 406.4117 - val_accuracy: 0.0000e+00 - val_mse: 406.1512\n",
      "Epoch 3/3\n",
      "278/278 [==============================] - 55s 196ms/step - loss: 468.3658 - accuracy: 4.5040e-04 - mse: 468.1029 - val_loss: 422.1701 - val_accuracy: 0.0000e+00 - val_mse: 421.9049\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 422.1701 - accuracy: 0.0000e+00 - mse: 421.9049\n",
      "Model Score: [422.17010498046875, 0.0, 421.9049072265625]\n"
     ]
    }
   ],
   "source": [
    "#define the inputs (shape of the incoming data)\n",
    "inputs = tf.keras.Input(shape=(image_height,image_width,3))\n",
    "\n",
    "x = inputs\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "\n",
    "#MODEL COMPILATION TIME\n",
    "model.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    #metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])   <-- Don't understand this output\n",
    "    metrics =  ['accuracy', 'mse']) # <-- So I picked this one\n",
    "\n",
    "data_augmentation = ImageDataGenerator( #Slightly changes each image by randomizing certain variables creating slight variations per epoch\n",
    "    rotation_range = 15, \n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.1,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "history = model.fit( #Final model fit\n",
    "    data_augmentation.flow(x_train,y_train,batch_size=32),\n",
    "    validation_data = (x_test,y_test),\n",
    "    steps_per_epoch = len(x_train) // 32,\n",
    "    epochs = 3\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Model Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Score: {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e809461369eb0678bfaf0e3134bd2805d4aee86c34f1ae2cb59ea6bbb98d97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
