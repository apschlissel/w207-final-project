{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51a61266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "885f4b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 20, 20, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and resizing image data \n",
    "path = \"/Users/madelinewhitlow/Desktop/MIDS_W207/petfinder-pawpularity-score/train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df['path'] = '/Users/madelinewhitlow/Desktop/MIDS_W207/petfinder-pawpularity-score/train/'+df['Id'] + '.jpg'\n",
    "csv_path = \"/Users/madelinewhitlow/Desktop/MIDS_W207/petfinder-pawpularity-score/train.csv\"\n",
    "\n",
    "df['img'] = df['path'].apply(lambda x: Image.open(x).convert(\"RGB\").resize((20,20)))\n",
    "#df['img'] = df['path'].apply(lambda x: ImageOps.grayscale(Image.open(x).resize((20,20))))\n",
    "\n",
    "\n",
    "df['img_array'] = df['img'].apply(lambda x: img_to_array(x)/255)\n",
    "\n",
    "#print(trainMdata.head())\n",
    "labels=[]\n",
    "imgArr=[]\n",
    "\n",
    "for ind in df.index:\n",
    "    img = df.img_array[0]\n",
    "    imgArr.append(img)\n",
    "    labels.append(df['Pawpularity'][ind])\n",
    "\n",
    "labels = np.array(labels)\n",
    "X_train=np.array(imgArr, dtype=float)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91838152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (9912, 20, 20, 3)\n",
      "label shape: (9912,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7921, 101)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "\n",
    "X_train, labels = X_train[shuffle], labels[shuffle]\n",
    "\n",
    "print('data shape: ', X_train.shape)\n",
    "print('label shape:', labels.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X_train[8916:], labels[8916:]\n",
    "dev_data, dev_labels = X_train[7920:8916], labels[7920:8916]\n",
    "train_data, train_labels = X_train[:7921], labels[:7921]\n",
    "\n",
    "\n",
    "test_labels1 = to_categorical(test_labels)\n",
    "train_labels2 = to_categorical(train_labels)\n",
    "train_labels2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "290de7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "248/248 [==============================] - 4s 12ms/step - loss: 0.0628 - accuracy: 0.0222 - val_loss: 0.0521 - val_accuracy: 0.0271\n",
      "Epoch 2/3\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 0.0537 - accuracy: 0.0307 - val_loss: 0.0523 - val_accuracy: 0.0361\n",
      "Epoch 3/3\n",
      "248/248 [==============================] - 3s 12ms/step - loss: 0.0532 - accuracy: 0.0303 - val_loss: 0.0521 - val_accuracy: 0.0271\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.0271\n",
      "\n",
      "Test loss: 0.05208967998623848\n",
      "Test accuracy: 0.027108434587717056\n"
     ]
    }
   ],
   "source": [
    "shape = (20,20, 3)\n",
    "\n",
    "# switch out activation to 'sigmoid'\n",
    "# try different pixel amounts (100x100) (20x20) etc\n",
    "#try binary crosstentropy vs categorical \n",
    "#adjust epochs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten \n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer with 20 filters\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    \n",
    "# add 2D pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "# flatten data\n",
    "model.add(Flatten())\n",
    "    \n",
    "# add a dense all-to-all relu layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "# apply dropout with rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "# soft-max layer\n",
    "model.add(Dense(101, activation='softmax'))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "model.fit(train_data,train_labels2, validation_data=(test_data, test_labels1), epochs=3)\n",
    "# evaluate the model\n",
    "score = model.evaluate(test_data, test_labels1, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45fe18b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fada42cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.008032128514056224\n"
     ]
    }
   ],
   "source": [
    "train_data_temp = train_data.reshape(7921,30000)\n",
    "test_data_temp = test_data.reshape(996, 30000)\n",
    "\n",
    "model1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model1.fit(train_data_temp, train_labels)\n",
    "test_predicted_labels = model1.predict(test_data_temp)\n",
    "print(\"accuracy: \",metrics.accuracy_score(test_labels, test_predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb66a3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Model (Binary) accuracy: 0.0231\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_model1 = BernoulliNB()\n",
    "naive_bayes_model1.fit(train_data_temp, train_labels)\n",
    "print ('Bernoulli Model accuracy: %3.4f' %naive_bayes_model1.score(test_data_temp, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4468749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7921,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8742bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "247/247 [==============================] - 9s 28ms/step - loss: 0.4700 - rmse: 0.5214 - mae: 0.3867 - mape: 376768896.0000 - val_loss: 0.2036 - val_rmse: 0.1063 - val_mae: 0.0386 - val_mape: 28447170.0000\n",
      "Epoch 2/3\n",
      "247/247 [==============================] - 6s 26ms/step - loss: 0.2426 - rmse: 0.2290 - mae: 0.1674 - mape: 157577712.0000 - val_loss: 0.1987 - val_rmse: 0.1048 - val_mae: 0.0343 - val_mape: 24181192.0000\n",
      "Epoch 3/3\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2055 - rmse: 0.1435 - mae: 0.0888 - mape: 79040712.0000 - val_loss: 0.1917 - val_rmse: 0.0992 - val_mae: 0.0253 - val_mape: 15542776.0000\n"
     ]
    }
   ],
   "source": [
    "# model from kaggle page \n",
    "# https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1\n",
    "\n",
    "# this accuracy seems ot be higher we could mess around with different filters/padding etc\n",
    "\n",
    "inputs = tf.keras.Input(shape=(20,20,3))\n",
    "\n",
    "#start off with x just being those inputs\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range = 15, \n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.1,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")\n",
    "history = model.fit(\n",
    "    data_augmentation.flow(train_data,train_labels2,batch_size=32),\n",
    "    validation_data = (test_data, test_labels1),\n",
    "    steps_per_epoch = len(train_data) // 32,\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "affa9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1917 - rmse: 0.0992 - mae: 0.0253 - mape: 15542776.0000\n",
      "Test accuracy: 0.0991794690489769\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_labels1, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d47721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
