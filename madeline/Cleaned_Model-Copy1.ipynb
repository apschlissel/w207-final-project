{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45e3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten \n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6d1a8",
   "metadata": {},
   "source": [
    "# Data Cleaning & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06d2cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (98, 224, 224, 3)\n",
      "Labels Shape; (98,)\n",
      "<bound method NDFrame.head of                                   Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
      "0   0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
      "1   0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
      "2   0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
      "3   0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
      "4   001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
      "..                               ...            ...   ...   ...   ...     ...   \n",
      "93  028d7652721dfd8643af1c9b21603af0              0     1     1     1       0   \n",
      "94  029141b506deb62d9c9e30cb52c952c4              0     1     1     1       0   \n",
      "95  029eb81eec4951bf0919743a0fdc3ebc              0     1     1     1       0   \n",
      "96  02a5a6417e5eb9694203e348741f76d0              0     1     1     1       0   \n",
      "97  02b40c9bb4aa551021c925e8f301f879              0     1     1     1       0   \n",
      "\n",
      "    Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
      "0           0      1        0      0          0     0     0           63   \n",
      "1           0      0        0      0          0     0     0           42   \n",
      "2           0      0        0      1          1     0     0           28   \n",
      "3           0      0        0      0          0     0     0           15   \n",
      "4           0      1        0      0          0     0     0           72   \n",
      "..        ...    ...      ...    ...        ...   ...   ...          ...   \n",
      "93          0      0        0      0          1     1     0           41   \n",
      "94          0      0        0      0          0     0     0           60   \n",
      "95          0      1        0      0          0     0     0           41   \n",
      "96          0      0        0      0          0     0     0           49   \n",
      "97          0      0        0      0          0     0     0           41   \n",
      "\n",
      "                                                 path  \\\n",
      "0   /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "1   /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "2   /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "3   /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "4   /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "..                                                ...   \n",
      "93  /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "94  /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "95  /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "96  /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "97  /Users/vviswanathan/Documents/GitHub/w207-fina...   \n",
      "\n",
      "                                                  img  cuteness_bin  \\\n",
      "0   <PIL.Image.Image image mode=RGB size=224x224 a...             6   \n",
      "1   <PIL.Image.Image image mode=RGB size=224x224 a...             4   \n",
      "2   <PIL.Image.Image image mode=RGB size=224x224 a...             2   \n",
      "3   <PIL.Image.Image image mode=RGB size=224x224 a...             1   \n",
      "4   <PIL.Image.Image image mode=RGB size=224x224 a...             7   \n",
      "..                                                ...           ...   \n",
      "93  <PIL.Image.Image image mode=RGB size=224x224 a...             4   \n",
      "94  <PIL.Image.Image image mode=RGB size=224x224 a...             5   \n",
      "95  <PIL.Image.Image image mode=RGB size=224x224 a...             4   \n",
      "96  <PIL.Image.Image image mode=RGB size=224x224 a...             4   \n",
      "97  <PIL.Image.Image image mode=RGB size=224x224 a...             4   \n",
      "\n",
      "                                            img_array  \n",
      "0   [[[-12120.102, -11443.831, -10185.46], [-12120...  \n",
      "1   [[[0.58431375, 0.57254905, 0.6], [0.56078434, ...  \n",
      "2   [[[0.6745098, 0.65882355, 0.5137255], [0.67843...  \n",
      "3   [[[0.84705883, 0.8784314, 0.8901961], [0.85882...  \n",
      "4   [[[0.7607843, 0.8235294, 0.8627451], [0.752941...  \n",
      "..                                                ...  \n",
      "93  [[[0.75686276, 0.5529412, 0.26666668], [0.7490...  \n",
      "94  [[[0.09803922, 0.06666667, 0.050980393], [0.08...  \n",
      "95  [[[0.8666667, 0.81960785, 0.65882355], [0.8705...  \n",
      "96  [[[0.9254902, 0.85882354, 0.75686276], [0.9686...  \n",
      "97  [[[0.99215686, 0.99215686, 0.99215686], [0.996...  \n",
      "\n",
      "[98 rows x 18 columns]>\n",
      "['Eyes', 'Face', 'Near', 'Group', 'n06359193', 'n03729826', 'n01930112']\n"
     ]
    }
   ],
   "source": [
    "# importing and resizing image data \n",
    "# change path to wherever your data lives on your computer\n",
    "csv_path = \"/Users/vviswanathan/Documents/GitHub/w207-final-project/petfinder-pawpularity-score/train.csv\"\n",
    "image_path = '/Users/vviswanathan/Documents/GitHub/w207-final-project/petfinder-pawpularity-score/train/'\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "def CutenessBuckets(pawpularity_score):\n",
    "    if pawpularity_score <= 10:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 20:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 30:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 40:\n",
    "        return 3\n",
    "    elif pawpularity_score <= 50:\n",
    "        return 4\n",
    "    elif pawpularity_score <= 60:\n",
    "        return 5\n",
    "    elif pawpularity_score <= 70:\n",
    "        return 6\n",
    "    elif pawpularity_score <= 80:\n",
    "        return 7\n",
    "    elif pawpularity_score <= 90:\n",
    "        return 8\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 9\n",
    "\n",
    "def getAdditionalTags(model, imArr):\n",
    "    tags=[]\n",
    "    im = np.expand_dims(imArr, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    preds = model.predict(im)\n",
    "    #print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "    return decode_predictions(preds, top=3)[0][0][0], decode_predictions(preds, top=3)[0][1][0], decode_predictions(preds, top=3)[0][2][0] \n",
    "    #return tags\n",
    "\n",
    "def CleanandProcessData(csv_path, image_path, image_resize):\n",
    "\n",
    "    # creating path to image using the id in the data frame we've created\n",
    "    df['path'] = image_path + df['Id'] + '.jpg'\n",
    "    df['img'] = df['path'].apply(lambda x: Image.open(x).convert(\"RGB\").resize((image_resize,image_resize)))\n",
    "    \n",
    "    df['cuteness_bin'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "    df['img_array'] = df['img'].apply(lambda x: img_to_array(x)/255)\n",
    "\n",
    "    labels_raw=[]\n",
    "    labels_bin = []\n",
    "    imgArr=[]\n",
    "    tags=[]\n",
    "\n",
    "    for ind in df.index:\n",
    "        tags_data=[]\n",
    "        img = df.img_array[0]\n",
    "        t1,t2,t3=getAdditionalTags(model, img)\n",
    "        imgArr.append(img)\n",
    "        labels_raw.append(df['Pawpularity'][ind])\n",
    "        labels_bin.append(df['cuteness_bin'][ind])\n",
    "        \n",
    "        #append all metadata in the dataframe as tags\n",
    "        if (df['Subject Focus'][ind]==1):\n",
    "            tags_data.append('Subject Focus')\n",
    "        if (df['Eyes'][ind] ==1):\n",
    "            tags_data.append('Eyes')\n",
    "        if (df['Face'][ind] ==1):\n",
    "            tags_data.append('Face')\n",
    "        if (df['Near'][ind] ==1):\n",
    "            tags_data.append('Near')\n",
    "        if (df['Accessory'][ind] ==1):\n",
    "            tags_data.append('Accessory')\n",
    "        if (df['Group'][ind] ==1):\n",
    "            tags_data.append('Group')\n",
    "        if (df['Collage'][ind] ==1):\n",
    "            tags_data.append('Collage')\n",
    "        if (df['Human'][ind] ==1):\n",
    "            tags_data.append('Human')\n",
    "        if (df['Occlusion'][ind] ==1):\n",
    "            tags_data.append('Occlusion')\n",
    "        if (df['Info'][ind] ==1):\n",
    "            tags_data.append('Info')\n",
    "        if (df['Blur'][ind] ==1):\n",
    "            tags_data.append('Info')\n",
    "        tags_data.append(t1)\n",
    "        tags_data.append(t2)\n",
    "        tags_data.append(t3)\n",
    "        tags.append(tags_data)\n",
    "    #print(tags_data)\n",
    "    labels_raw = np.array(labels_raw)\n",
    "    labels_bin = np.array(labels_bin)\n",
    "    tags= np.array(tags,dtype=object)\n",
    "    X_train=np.array(imgArr, dtype=float)\n",
    "    print('Training Shape:',X_train.shape)\n",
    "    print('Labels Shape;', labels_raw.shape)\n",
    "    return X_train, labels_raw, labels_bin, tags\n",
    "\n",
    "# imnporting csv with image ids and pawpularity scores\n",
    "df = pd.read_csv(csv_path)\n",
    "X_train, labels_raw, labels_bin, tags = CleanandProcessData(csv_path, image_path, 224)\n",
    "print(df.head)\n",
    "print(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600ca3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (98, 224, 224, 3)\n",
      "pawpularity label shape: (98,)\n",
      "bin label shape: (98,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffling data and separating into train, test and dev sets\n",
    "shuffle = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, labels_raw, labels_bin = X_train[shuffle], labels_raw[shuffle], labels_bin[shuffle]\n",
    "\n",
    "print('data shape: ', X_train.shape)\n",
    "print('pawpularity label shape:', labels_raw.shape)\n",
    "print('bin label shape:', labels_bin.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "train_data, train_labels_raw, train_labels_bin = X_train[:7921], labels_raw[:7921], labels_bin[:7921]\n",
    "test_data, test_labels_raw, test_labels_bin = X_train[8916:], labels_raw[8916:], labels_bin[8916:]\n",
    "dev_data, dev_labels_raw, dev_labels_bin = X_train[7920:8916], labels_raw[7920:8916], labels_bin[7920:8916]\n",
    "\n",
    "#train_data, train_labels_raw, train_labels_bin, train_tags = X_train[:79], labels_raw[:79], labels_bin[:79], tags[:79]\n",
    "#test_data, test_labels_raw, test_labels_bin, test_tags = X_train[89:], labels_raw[89:], labels_bin[89:], tags[:89]\n",
    "#dev_data, dev_labels_raw, dev_labels_bin, dev_tags = X_train[79:89], labels_raw[79:89], labels_bin[79:89], tags[79:89]\n",
    "\n",
    "# raw labels (ie original pawpularity score)\n",
    "test_labels_category = to_categorical(test_labels_raw)\n",
    "train_labels_category = to_categorical(train_labels_raw)\n",
    "dev_labels_category = to_categorical(dev_labels_raw)\n",
    "\n",
    "# bucketed labels \n",
    "test_labels_bins_category = to_categorical(test_labels_bin)\n",
    "train_labels_bins_category = to_categorical(train_labels_bin)\n",
    "dev_labels_bins_category = to_categorical(dev_labels_bin)\n",
    "\n",
    "# blurred image data (optional use)\n",
    "blurred_train = gaussian_filter(train_data, sigma=1)\n",
    "blurred_test = gaussian_filter(test_data, sigma = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ee56d",
   "metadata": {},
   "source": [
    "# First CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3e2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- CNN Model 1 with all Paw scores ----------\n",
      "train_data (79, 224, 224, 3)\n",
      "train_lables_cat (79, 101)\n",
      "test_data (9, 224, 224, 3)\n",
      "test_lables_cat (9, 101)\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 6s 2s/step - loss: 126788.3516 - accuracy: 0.0127 - val_loss: 28015.2070 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 5s 1s/step - loss: 20427.8379 - accuracy: 0.0253 - val_loss: 9792.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 4s 1s/step - loss: 6318.9629 - accuracy: 0.0253 - val_loss: 4.6133 - val_accuracy: 0.1111\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.6133 - accuracy: 0.1111\n",
      "\n",
      "Test loss: 4.613306999206543\n",
      "Test accuracy: 0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "possible_outcomes = 101\n",
    "# first model attempt (using raw pawpularity scores)\n",
    "# switch out activation to 'sigmoid'\n",
    "# try different pixel amounts (100x100) (20x20) etc\n",
    "#try binary crosstentropy vs categorical \n",
    "#adjust epochs\n",
    "\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer with 20 filters\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    \n",
    "# add 2D pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "# flatten data\n",
    "model.add(Flatten())\n",
    "    \n",
    "# add a dense all-to-all relu layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "# apply dropout with rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "# soft-max layer\n",
    "model.add(Dense(possible_outcomes, activation='softmax'))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "\n",
    "print('-'*10, 'CNN Model 1 with all Paw scores', '-'*10)\n",
    "print(\"train_data\",train_data.shape )\n",
    "print(\"train_lables_cat\",train_labels_category.shape )\n",
    "print(\"test_data\",test_data.shape )\n",
    "print(\"test_lables_cat\",test_labels_category.shape )\n",
    "\n",
    "model.fit(train_data,train_labels_category, validation_data=(test_data, test_labels_category), epochs=3)\n",
    "# evaluate the model\n",
    "score = model.evaluate(test_data, test_labels_category, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119c77f",
   "metadata": {},
   "source": [
    "# Same Model but using 10 category buckets for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93f6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- CNN Model 1 with all Paw scores ----------\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 7s 2s/step - loss: 217338.3750 - accuracy: 0.1392 - val_loss: 57055.8203 - val_accuracy: 0.2222\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 5s 2s/step - loss: 47199.1055 - accuracy: 0.1646 - val_loss: 2.3002 - val_accuracy: 0.1111\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 4s 1s/step - loss: 26.0652 - accuracy: 0.1392 - val_loss: 1146.2106 - val_accuracy: 0.1111\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1146.2106 - accuracy: 0.1111\n",
      "\n",
      "Test loss: 1146.2105712890625\n",
      "Test accuracy: 0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "possible_outcomes = 10\n",
    "# first model attempt (using raw pawpularity scores)\n",
    "# switch out activation to 'sigmoid'\n",
    "# try different pixel amounts (100x100) (20x20) etc\n",
    "#try binary crosstentropy vs categorical \n",
    "#adjust epochs\n",
    "\n",
    "\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add second convolutional layer with 20 filters\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    \n",
    "# add 2D pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "# flatten data\n",
    "model.add(Flatten())\n",
    "    \n",
    "# add a dense all-to-all relu layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "# apply dropout with rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "# soft-max layer\n",
    "model.add(Dense(possible_outcomes, activation='softmax'))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "\n",
    "print('-'*10, 'CNN Model 1 with all Paw scores', '-'*10)\n",
    "model.fit(train_data,train_labels_bins_category, validation_data=(test_data, test_labels_bins_category), epochs=3)\n",
    "# evaluate the model\n",
    "score = model.evaluate(test_data, test_labels_bins_category, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c8e2d",
   "metadata": {},
   "source": [
    "# Second CNN Model - Using raw paw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0dfc208",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flow() got multiple values for argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-57896d2e86ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m history = model.fit(\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_category\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: flow() got multiple values for argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "# model from kaggle page \n",
    "# https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1\n",
    "\n",
    "# this accuracy seems ot be higher we could mess around with different filters/padding etc\n",
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "tags_input = tf.keras.Input(shape=shape)\n",
    "#start off with x just being those inputs\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = [inputs, tags_input], outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range = 15, \n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.1,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "history = model.fit(\n",
    "    data_augmentation.flow(train_data, train_tags, train_labels_category,batch_size=32),\n",
    "    validation_data = (test_data, test_tags, test_labels_category),\n",
    "    steps_per_epoch = len(train_data) // 32,\n",
    "    epochs = 3\n",
    ")\n",
    "score = model.evaluate(test_data, test_labels_category, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2414c",
   "metadata": {},
   "source": [
    "# Second CNN Model - Using bucket paw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model from kaggle page \n",
    "# https://www.kaggle.com/alexteboul/tutorial-part-3-cnn-image-modeling-1\n",
    "\n",
    "# this accuracy seems ot be higher we could mess around with different filters/padding etc\n",
    "shape = (train_data.shape[1],train_data.shape[2], train_data.shape[3])\n",
    "inputs = tf.keras.Input(shape=shape)\n",
    "\n",
    "#start off with x just being those inputs\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'mse', \n",
    "    optimizer = 'Adam', \n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"])\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range = 15, \n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.1,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")\n",
    "history = model.fit(\n",
    "    data_augmentation.flow(train_data,train_labels_bins_category,batch_size=32),\n",
    "    validation_data = (test_data, test_labels_bins_category),\n",
    "    steps_per_epoch = len(train_data) // 32,\n",
    "    epochs = 3\n",
    ")\n",
    "score = model.evaluate(test_data, test_labels_bins_category, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f8c46",
   "metadata": {},
   "source": [
    "# Trying other models (Naive Bayes & KNN) - raw paw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other model attempts:\n",
    "# have to reshape the data to input it into a different model\n",
    "train_size = train_data.shape[0]\n",
    "train_shape = train_data.shape[1]*train_data.shape[2]*train_data.shape[3]\n",
    "\n",
    "test_size = test_data.shape[0]\n",
    "test_shape = test_data.shape[1]*test_data.shape[2]*test_data.shape[3]\n",
    "\n",
    "train_data_temp = train_data.reshape(train_size,train_shape)\n",
    "test_data_temp = test_data.reshape(test_size,test_shape)\n",
    "print('-'*10, ' K Nearest Neighbor ', '-'*10)\n",
    "for k in [1,2,3,5,7]:\n",
    "    knnmodel = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnmodel.fit(train_data_temp, train_labels_raw)\n",
    "    test_predicted_labels = knnmodel.predict(test_data_temp)\n",
    "    print(\"accuracy with k=\", k, \" : \", metrics.accuracy_score(test_labels_raw, test_predicted_labels))\n",
    "\n",
    "\n",
    "print('-'*10, 'Naive Bayes ', '-'*10)\n",
    "naive_bayes_model1 = BernoulliNB()\n",
    "naive_bayes_model1.fit(train_data_temp, train_labels_raw)\n",
    "print ('Bernoulli Model accuracy: %3.4f' %naive_bayes_model1.score(test_data_temp, test_labels_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*10, ' K Nearest Neighbor ', '-'*10)\n",
    "for k in [1,2,3,5,7]:\n",
    "    knnmodel = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnmodel.fit(train_data_temp, train_labels_bin)\n",
    "    test_predicted_labels = knnmodel.predict(test_data_temp)\n",
    "    print(\"accuracy with k=\", k, \" : \", metrics.accuracy_score(test_labels_bin, test_predicted_labels))\n",
    "\n",
    "print('-'*10, 'Naive Bayes ', '-'*10)\n",
    "naive_bayes_model1 = BernoulliNB()\n",
    "naive_bayes_model1.fit(train_data_temp, train_labels_bin)\n",
    "print ('Bernoulli Model accuracy: %3.4f' %naive_bayes_model1.score(test_data_temp, test_labels_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0f763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec753800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeeb565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc06541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CutenessBuckets_2(pawpularity_score):\n",
    "    if pawpularity_score <= 50:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "def CutenessBuckets_3(pawpularity_score):\n",
    "    if pawpularity_score <= 33:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 66:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 2\n",
    "\n",
    "def CutenessBuckets_4(pawpularity_score):\n",
    "    if pawpularity_score <= 25:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 50:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 75:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 3\n",
    "df['cuteness_bin10'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "df['cuteness_bin2'] = df['Pawpularity'].apply(CutenessBuckets_2)\n",
    "df['cuteness_bin3'] = df['Pawpularity'].apply(CutenessBuckets_3)\n",
    "df['cuteness_bin4'] = df['Pawpularity'].apply(CutenessBuckets_4)\n",
    "\n",
    "labels_raw10 = np.array(df['cuteness_bin10'])\n",
    "labels_raw2 = np.array(df['cuteness_bin2'])\n",
    "labels_raw3 = np.array(df['cuteness_bin3'])\n",
    "labels_raw4 = np.array(df['cuteness_bin4'])\n",
    "\n",
    "train_labels_raw10 =  labels_raw10[:7921]\n",
    "test_labels_raw10 = labels_raw10[8916:]\n",
    "\n",
    "train_labels_raw2 =  labels_raw2[:7921]\n",
    "test_labels_raw2 = labels_raw2[8916:]\n",
    "\n",
    "train_labels_raw3 =  labels_raw3[:7921]\n",
    "test_labels_raw3 = labels_raw3[8916:]\n",
    "\n",
    "train_labels_raw4 =  labels_raw4[:7921]\n",
    "test_labels_raw4 = labels_raw4[8916:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_list = [train_labels_raw10, train_labels_raw2, train_labels_raw3, train_labels_raw4]\n",
    "test_labels_list = [test_labels_raw10, test_labels_raw2, test_labels_raw3, test_labels_raw4]\n",
    "bucket_list = [10,2,3,4]\n",
    "for k in [1,2,3,5,7]:\n",
    "    for i in range(len(train_labels_list)):\n",
    "        knnmodel = KNeighborsClassifier(n_neighbors=k)\n",
    "        knnmodel.fit(train_data_temp, train_labels_list[i])\n",
    "        test_predicted_labels = knnmodel.predict(test_data_temp)\n",
    "        print(\"bucket size = :\" ,bucket_list[i])\n",
    "        print(\"accuracy with k=\", k, \" : \", metrics.accuracy_score(test_labels_list[i], test_predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2220af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_labels_list)):\n",
    "    naive_bayes_model1 = BernoulliNB()\n",
    "    naive_bayes_model1.fit(train_data_temp, train_labels_list[i])\n",
    "    print(\"bucket size = :\" ,bucket_list[i])\n",
    "    print ('Bernoulli Model accuracy: %3.4f' %naive_bayes_model1.score(test_data_temp, test_labels_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = image_path + df['Id'] + '.jpg'\n",
    "df = df.head(500)\n",
    "df['img'] = df['path'].apply(lambda x: Image.open(x).convert(\"RGB\").resize((224,224)))\n",
    "\n",
    "df['cuteness_bin'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "df['img_array'] = df['img'].apply(lambda x: img_to_array(x)/255)\n",
    "\n",
    "labels_raw=[]\n",
    "labels_bin = []\n",
    "imgArr=[]\n",
    "\n",
    "for ind in df.index:\n",
    "    img = df.img_array[0]\n",
    "    imgArr.append(img)\n",
    "    labels_raw.append(df['Pawpularity'][ind])\n",
    "    labels_bin.append(df['cuteness_bin'][ind])\n",
    "\n",
    "labels_raw = np.array(labels_raw)\n",
    "labels_bin = np.array(labels_bin)\n",
    "X_train=np.array(imgArr, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet50(weights='imagenet')\n",
    "\n",
    "\n",
    "def getAdditionalTags(model, imArr):\n",
    "    tags=[]\n",
    "    im = np.expand_dims(imArr, axis=0)\n",
    "    im = preprocess_input(im)\n",
    "    preds = model.predict(im)\n",
    "    #print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "    tags.append(decode_predictions(preds, top=3)[0][0][0])\n",
    "    tags.append(decode_predictions(preds, top=3)[0][1][0])   \n",
    "    tags.append(decode_predictions(preds, top=3)[0][2][0]) \n",
    "    return tags\n",
    "    \n",
    "def augmentExif(img,df):\n",
    "    exifData = img._getexif()\n",
    "    if exifData is None:\n",
    "        return\n",
    "    else:\n",
    "        print (type(exifData))\n",
    "        for tagId in exifData:\n",
    "            # get the tag name, instead of human unreadable tag id\n",
    "            tag = TAGS.get(tagId, tagId)\n",
    "            data = exifdata.get(tagId)\n",
    "            # decode bytes \n",
    "            if isinstance(data, bytes):\n",
    "                data = data.decode()\n",
    "                print(f\"{tag:25}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c63e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "getAdditionalTags(model,imgArr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad98764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd86fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
