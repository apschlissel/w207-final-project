{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffafa64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 17:03:53.882175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-06 17:03:53.882221: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "#image stuff\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "#sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882643d",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784651f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and resizing image data \n",
    "# change path to wherever your data lives on your computer\n",
    "csv_path = \"/home/jovyan/w207-final-project/data/train.csv\"\n",
    "image_path = '/home/jovyan/w207-final-project/data/train/'\n",
    "\n",
    "def CutenessBuckets(pawpularity_score):\n",
    "    if pawpularity_score <= 10:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 20:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 30:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 40:\n",
    "        return 3\n",
    "    elif pawpularity_score <= 50:\n",
    "        return 4\n",
    "    elif pawpularity_score <= 60:\n",
    "        return 5\n",
    "    elif pawpularity_score <= 70:\n",
    "        return 6\n",
    "    elif pawpularity_score <= 80:\n",
    "        return 7\n",
    "    elif pawpularity_score <= 90:\n",
    "        return 8\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 9\n",
    "\n",
    "def CleanandProcessData(csv_path, image_path, image_resize):\n",
    "\n",
    "    # imnporting csv with image ids and pawpularity scores\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # creating path to image using the id in the data frame we've created\n",
    "    df['path'] = image_path + df['Id'] + '.jpg'\n",
    "    df['img'] = df['path'].apply(lambda x: Image.open(x).convert(\"RGB\").resize((image_resize,image_resize)))\n",
    "    \n",
    "    df['cuteness_bin'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "    df['img_array'] = df['img'].apply(lambda x: img_to_array(x)/255)\n",
    "\n",
    "    labels_raw=[]\n",
    "    labels_bin = []\n",
    "    imgArr=[]\n",
    "\n",
    "    for ind in df.index:\n",
    "        img = df.img_array[0]\n",
    "        imgArr.append(img)\n",
    "        labels_raw.append(df['Pawpularity'][ind])\n",
    "        labels_bin.append(df['cuteness_bin'][ind])\n",
    "\n",
    "    labels_raw = np.array(labels_raw)\n",
    "    labels_bin = np.array(labels_bin)\n",
    "    X_train=np.array(imgArr, dtype=float)\n",
    "    print('Training Shape:',X_train.shape)\n",
    "    print('Labels Shape;', labels_raw.shape)\n",
    "    return X_train, labels_raw, labels_bin\n",
    "\n",
    "X_train, labels_raw, labels_bin = CleanandProcessData(csv_path, image_path, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data and separating into train, test and dev sets\n",
    "shuffle = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "\n",
    "X_train, labels_raw, labels_bin = X_train[shuffle], labels_raw[shuffle], labels_bin[shuffle]\n",
    "\n",
    "print('data shape: ', X_train.shape)\n",
    "print('pawpularity label shape:', labels_raw.shape)\n",
    "print('bin label shape:', labels_bin.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "train_data, train_labels_raw, train_labels_bin = X_train[:7921], labels_raw[:7921], labels_bin[:7921]\n",
    "test_data, test_labels_raw, test_labels_bin = X_train[8916:], labels_raw[8916:], labels_bin[8916:]\n",
    "dev_data, dev_labels_raw, dev_labels_bin = X_train[7920:8916], labels_raw[7920:8916], labels_bin[7920:8916]\n",
    "\n",
    "# raw labels (ie original pawpularity score)\n",
    "test_labels_category = to_categorical(test_labels_raw)\n",
    "train_labels_category = to_categorical(train_labels_raw)\n",
    "dev_labels_category = to_categorical(dev_labels_raw)\n",
    "\n",
    "# bucketed labels \n",
    "test_labels_bins_category = to_categorical(test_labels_bin)\n",
    "train_labels_bins_category = to_categorical(train_labels_bin)\n",
    "dev_labels_bins_category = to_categorical(dev_labels_bin)\n",
    "\n",
    "# blurred image data (optional use)\n",
    "blurred_train = gaussian_filter(train_data, sigma=1)\n",
    "blurred_test = gaussian_filter(test_data, sigma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb75d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical ML models\n",
    "# have to reshape the data to input it into a different model\n",
    "train_size = train_data.shape[0]\n",
    "train_shape = train_data.shape[1]*train_data.shape[2]*train_data.shape[3]\n",
    "\n",
    "dev_size = dev_data.shape[0]\n",
    "dev_shape = dev_data.shape[1]*dev_data.shape[2]*dev_data.shape[3]\n",
    "\n",
    "test_size = test_data.shape[0]\n",
    "test_shape = test_data.shape[1]*test_data.shape[2]*test_data.shape[3]\n",
    "\n",
    "train_data_temp = train_data.reshape(train_size,train_shape)\n",
    "dev_data_temp = dev_data.reshape(dev_size,dev_shape)\n",
    "test_data_temp = test_data.reshape(test_size,test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buckets\n",
    "def CutenessBuckets_2(pawpularity_score):\n",
    "    if pawpularity_score <= 50:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "def CutenessBuckets_3(pawpularity_score):\n",
    "    if pawpularity_score <= 33:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 66:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 2\n",
    "\n",
    "def CutenessBuckets_4(pawpularity_score):\n",
    "    if pawpularity_score <= 25:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 50:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 75:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 3\n",
    "    \n",
    "def CutenessBuckets_5(pawpularity_score):\n",
    "    if pawpularity_score <= 20:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 40:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 60:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 80:\n",
    "        return 3\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 4\n",
    "    \n",
    "def CutenessBuckets_7(pawpularity_score):\n",
    "    if pawpularity_score <= 15:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 30:\n",
    "        return 1\n",
    "    elif pawpularity_score <= 45:\n",
    "        return 2\n",
    "    elif pawpularity_score <= 60:\n",
    "        return 3\n",
    "    elif pawpularity_score <= 75:\n",
    "        return 4\n",
    "    elif pawpularity_score <= 90:\n",
    "        return 5\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 6\n",
    "\n",
    "    \n",
    "def CutenessBuckets_2_diff_breakpoint(pawpularity_score):\n",
    "    if pawpularity_score <= 75:\n",
    "        return 0\n",
    "    elif pawpularity_score <= 100:\n",
    "        return 1\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df['cuteness_bin10'] = df['Pawpularity'].apply(CutenessBuckets)\n",
    "df['cuteness_bin2'] = df['Pawpularity'].apply(CutenessBuckets_2)\n",
    "df['cuteness_bin3'] = df['Pawpularity'].apply(CutenessBuckets_3)\n",
    "df['cuteness_bin4'] = df['Pawpularity'].apply(CutenessBuckets_4)\n",
    "df['cuteness_bin5'] = df['Pawpularity'].apply(CutenessBuckets_5)\n",
    "df['cuteness_bin7'] = df['Pawpularity'].apply(CutenessBuckets_7)\n",
    "df['CutenessBuckets_2_diff_breakpoint'] = df['Pawpularity'].apply(CutenessBuckets_2_diff_breakpoint)\n",
    "\n",
    "labels_raw10 = np.array(df['cuteness_bin10'])\n",
    "labels_raw2 = np.array(df['cuteness_bin2'])\n",
    "labels_raw3 = np.array(df['cuteness_bin3'])\n",
    "labels_raw4 = np.array(df['cuteness_bin4'])\n",
    "labels_raw5 = np.array(df['cuteness_bin5'])\n",
    "labels_raw7 = np.array(df['cuteness_bin7'])\n",
    "labels_raw2_diff = np.array(df['CutenessBuckets_2_diff_breakpoint'])\n",
    "\n",
    "train_labels_raw10 =  labels_raw10[:7921]\n",
    "dev_labels_raw10 =  labels_raw10[7920:8916]\n",
    "test_labels_raw10 = labels_raw10[8916:]\n",
    "\n",
    "train_labels_raw2 =  labels_raw2[:7921]\n",
    "dev_labels_raw2 =  labels_raw2[7920:8916]\n",
    "test_labels_raw2 = labels_raw2[8916:]\n",
    "\n",
    "train_labels_raw3 =  labels_raw3[:7921]\n",
    "dev_labels_raw3 =  labels_raw3[7920:8916]\n",
    "test_labels_raw3 = labels_raw3[8916:]\n",
    "\n",
    "train_labels_raw4 =  labels_raw4[:7921]\n",
    "dev_labels_raw4 =  labels_raw4[7920:8916]\n",
    "test_labels_raw4 = labels_raw4[8916:]\n",
    "\n",
    "train_labels_raw5 =  labels_raw5[:7921]\n",
    "dev_labels_raw5 =  labels_raw5[7920:8916]\n",
    "test_labels_raw5 = labels_raw5[8916:]\n",
    "\n",
    "train_labels_raw7 =  labels_raw7[:7921]\n",
    "dev_labels_raw7 =  labels_raw7[7920:8916]\n",
    "test_labels_raw7 = labels_raw7[8916:]\n",
    "\n",
    "train_labels_raw2diff =  labels_raw2_diff[:7921]\n",
    "dev_labels_raw2diff =  labels_raw2_diff[7920:8916]\n",
    "test_labels_raw2diff = labels_raw2_diff[8916:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b825f54",
   "metadata": {},
   "source": [
    "## Models - 4 Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e41e6",
   "metadata": {},
   "source": [
    "I chose 4 buckets because we were getting somewhat better performance with larger buckets, and I think it would still be insightful to have quartiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee6833",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "print('-'*10, 'Gradient Boosting Classifier ', '-'*10)\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "clf_gb.fit(train_data_temp, train_labels_raw4)\n",
    "preds = clf_gb.predict(dev_data_temp)\n",
    "print ('Gradient Boosting Model accuracy: %3.4f' %clf_gb.score(dev_data_temp, dev_labels_raw4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561db56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('-'*10, 'Random Forest Classifier ', '-'*10)\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(train_data_temp, train_labels_raw4)\n",
    "preds_rf = clf_rf.predict(dev_data_temp)\n",
    "print ('Random Forest Model accuracy: %3.4f' %clf_rf.score(dev_data_temp, dev_labels_raw4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a19bf0",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd8d56",
   "metadata": {},
   "source": [
    "We want to understand why our performance is pretty low. An error analysis can help with this. Is or model close, or is it far off from the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at gradient boosting preds\n",
    "diffs = dev_labels_raw4 - preds_gb\n",
    "\n",
    "#mean\n",
    "differences_mean = np.mean(np.absolute(diffs), dtype=np.float64)\n",
    "print('Mean differences: ', differences_mean)\n",
    "\n",
    "#get examples of most incorrect predictions\n",
    "#max\n",
    "result_max = np.where(differences_mean == np.amax(differences_mean))\n",
    "print('List of Indices of maximum element :', result_max[0])\n",
    "\n",
    "#min\n",
    "result_min = np.where(differences_mean == np.amin(differences_mean))\n",
    "print('List of Indices of minimum element :', result_min[0])\n",
    "\n",
    "#correct\n",
    "result_correct = np.where(differences_mean == 0)\n",
    "print('List of Indices of correct predictions:', result_correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
